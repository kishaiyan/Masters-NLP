{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6730fecf",
   "metadata": {},
   "source": [
    "# Assignment 2 \n",
    "### Kishaiyan Vellaichamy Thangaraj \n",
    "### A189309\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df2aac6",
   "metadata": {},
   "source": [
    "## A. Tasks as specified for your team structure\n",
    "\n",
    "**One headings for each task.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c788bab",
   "metadata": {},
   "source": [
    "*  **Reading the Dataset and decision of pre-processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Setting up the Environment**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591c75a6",
   "metadata": {},
   "source": [
    "* **Testing the Dataset with Spacy and nltk**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Making an Answer Extraction Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb005ad",
   "metadata": {},
   "source": [
    "## Setting up the Environment for Question And Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f01c553",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spacy==2.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a68736c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "492bb74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install neuralcoref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e91af281",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6eb5e117",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install sentence_transformers\n",
    "#pip install sckit-learn\n",
    "#pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7a595f",
   "metadata": {},
   "source": [
    "## Dataset Reading and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90115625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef1bed47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id               author        date  year month         topic  \\\n",
      "0  17307       Marlise Simons   1/01/2017  2017     1  architecture   \n",
      "1  17292          Andy Newman  31/12/2016  2016    12           art   \n",
      "2  17298  Emma G. Fitzsimmons   2/01/2017  2017     1      business   \n",
      "3  17311           Carl Hulse   3/01/2017  2017     1      business   \n",
      "4  17339        Jim Rutenberg   5/01/2017  2017     1      business   \n",
      "\n",
      "                                             article  \n",
      "0  PARIS  ?   When the Islamic State was about to...  \n",
      "1  Angels are everywhere in the Mu?iz family?s ap...  \n",
      "2  Finally. The Second Avenue subway opened in Ne...  \n",
      "3  WASHINGTON  ?   It?s   or   time for Republica...  \n",
      "4  For Megyn Kelly, the shift from Fox News to NB...  \n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('news_dataset.csv',encoding='iso-8859-1')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2afcab40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic Counts:\n",
      "politics         324\n",
      "business         208\n",
      "entertainment    153\n",
      "crime            110\n",
      "lifestyle         78\n",
      "law               41\n",
      "sports            30\n",
      "science           25\n",
      "technology        18\n",
      "architecture       4\n",
      "accidents          4\n",
      "art                2\n",
      "health             2\n",
      "environment        1\n",
      "Name: topic, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "topic_counts = data['topic'].value_counts()\n",
    "\n",
    "# Print the count of every topic\n",
    "print(\"Topic Counts:\")\n",
    "print(topic_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05850d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_document(document):\n",
    "    # Split the document into words\n",
    "    words = document.split()\n",
    "\n",
    "    # Check if the first word is all uppercase\n",
    "    if words[0].isupper():\n",
    "        # Find the index of the first question mark if it exists\n",
    "        try:\n",
    "            first_question_index = words.index('?')\n",
    "        except ValueError:\n",
    "            \n",
    "            first_question_index = len(words)\n",
    "\n",
    "        # Remove words until the first question mark (inclusive)\n",
    "        words = words[first_question_index:]\n",
    "\n",
    "    # Join the remaining words back into a string\n",
    "    result = ' '.join(words)\n",
    "    # Check if the first character of the result is not '?'\n",
    "    if result and result[0] != '?':\n",
    "        return result\n",
    "    else:\n",
    "        # Return the result without the first character if it starts with '?'\n",
    "        return result[1:]\n",
    "\n",
    "\n",
    "# Apply process_document to all documents in the 'article' column\n",
    "data['processed_article'] = data['article'].apply(process_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a69031f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data['processed_article'] = data['processed_article'].str.replace(\"?\", \"'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9832d0",
   "metadata": {},
   "source": [
    "## Coreference Resolution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9e25af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import neuralcoref\n",
    "nlp=spacy.load('en')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c6802e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x7fd701f28d10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuralcoref.add_to_pipe(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1230ca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test = data.loc[data['id'] == 17307, 'processed_article'].values[0]\n",
    "\n",
    "#function to retrieve the article with article number\n",
    "def getArticle(number):\n",
    "     return data.loc[data['id'] ==number, 'processed_article'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5319bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Syria: [Syria, Syria, the country],\n",
       " his: [his, he, his],\n",
       " mathematicians and designers: [mathematicians and designers, their],\n",
       " Palmyra: [Palmyra, it],\n",
       " This: [This, it],\n",
       " the stuff architects and archaeologists need: [the stuff architects and archaeologists need, They],\n",
       " Mr. Ubelmann: [Mr. Ubelmann, Mr. Ubelmann, he],\n",
       " Palmyra: [Palmyra, Palmyra, Palmyra, Palmyra],\n",
       " The terrorists: [The terrorists, them],\n",
       " the best response: [the best response, It, the show, it, it, the show, it, the multimedia show, it],\n",
       " these places: [these places, their, their],\n",
       " a war of images: [a war of images, that war],\n",
       " he: [he, his, he, He],\n",
       " global heritage: [global heritage, the Middle Eastern heritage],\n",
       " Mr. Ubelmann: [Mr. Ubelmann, he, he, his],\n",
       " We: [We, We, our],\n",
       " the archaeologists: [the archaeologists, the Syrian archaeologists],\n",
       " They: [They, their, their],\n",
       " our colleagues: [our colleagues, they],\n",
       " his team: [his team, The team],\n",
       " Islamists: [Islamists, their],\n",
       " Nimrud: [Nimrud, she],\n",
       " specialists: [specialists, they],\n",
       " The images from the drones in war zones: [The images from the drones in war zones, these],\n",
       " Syria: [Syria, Syria, Syria, Syria],\n",
       " Iraq: [Iraq, Iraq, Iraq],\n",
       " Mr. Butterlin: [Pascal Butterlin, a professor of archaeology at the Sorbonne in Paris, Mr. Butterlin, He, he, he],\n",
       " Mari: [Mari, Mari],\n",
       " Mr. Ali: [Cheikhmous Ali, a Syrian archaeologist based in France, who founded the international group the Association for the Protection of Syrian Archaeology, Mr. Ali, Mr. Ali, he, Mr. Hollande, Mr. Hollande, he],\n",
       " France: [France, France, France, France],\n",
       " jihadists: [jihadists, they],\n",
       " France was taking in more Syrian refugees trying to protect monuments of great historical and cultural importance: [France was taking in more Syrian refugees trying to protect monuments of great historical and cultural importance, we]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(test)\n",
    "\n",
    "doc._.has_coref\n",
    "coref_clusters=doc._.coref_clusters\n",
    "coref_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd3256c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coreference resolution\n",
    "class create_cluster():\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    neuralcoref.add_to_pipe(nlp)\n",
    "\n",
    "    coref_clusters = None  # Define coref_clusters at the class level\n",
    "\n",
    "    @staticmethod\n",
    "    def cluster(context):\n",
    "        doc = create_cluster.nlp(context)  # Access nlp using class name\n",
    "        if doc._.has_coref:\n",
    "            create_cluster.coref_clusters = doc._.coref_clusters  # Store clusters in class attribute\n",
    "\n",
    "    @staticmethod\n",
    "    def getClusters():\n",
    "        return create_cluster.coref_clusters  # Access coref_clusters using class name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc265cc",
   "metadata": {},
   "source": [
    "## Testing Matching Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "178b2d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d376064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_relevant_sentences_hf(context, question,num_context_sentences=0):\n",
    "    model_name = \"paraphrase-MiniLM-L6-v2\"  \n",
    "    model = SentenceTransformer(model_name)\n",
    "\n",
    "    create_cluster.cluster(context)\n",
    "    context_sentences = nltk.sent_tokenize(context)\n",
    "\n",
    "    # Encode the question and context\n",
    "    question_embedding = model.encode(question, convert_to_tensor=True)\n",
    "    context_embeddings = model.encode(context_sentences, convert_to_tensor=True)\n",
    "\n",
    "    # Compute cosine similarity between question and context sentences\n",
    "    cos_similarities = util.pytorch_cos_sim(question_embedding, context_embeddings)[0]\n",
    "\n",
    "    # Find the index of the sentence with the maximum similarity\n",
    "    max_similarity_index = cos_similarities.argmax().item()\n",
    "\n",
    "    start_index = max(0, max_similarity_index - num_context_sentences)\n",
    "    end_index = min(len(context_sentences) - 1, max_similarity_index + num_context_sentences)\n",
    "\n",
    "    context_paragraph = ' '.join(context_sentences[start_index:end_index + 1])\n",
    "\n",
    "    return context_paragraph #cos_similarities[max_similarity_index].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7261cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_relevant_sentences_tfidf(context, question, num_context_sentences=3):\n",
    "    # Tokenize context into sentences\n",
    "    create_cluster.cluster(context)\n",
    "    context_sentences = nltk.sent_tokenize(context)\n",
    "\n",
    "    # Tokenize question into words\n",
    "    question_words = nltk.word_tokenize(question.lower())\n",
    "\n",
    "    # Vectorize context sentences using TF-IDF\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(context_sentences)\n",
    "\n",
    "    # Calculate TF-IDF vector for the question\n",
    "    question_tfidf = tfidf_vectorizer.transform([' '.join(question_words)])\n",
    "\n",
    "    # Calculate cosine similarity between question TF-IDF vector and context TF-IDF matrix\n",
    "    cosine_similarities = cosine_similarity(question_tfidf, tfidf_matrix).flatten()\n",
    "\n",
    "    # Find the indices of top N most similar sentences\n",
    "    top_indices = cosine_similarities.argsort()[-num_context_sentences:][::-1]\n",
    "\n",
    "    # Extract relevant sentences\n",
    "    relevant_paragraph = ' '.join([context_sentences[i] for i in top_indices])\n",
    "\n",
    "    return relevant_paragraph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7e04bd",
   "metadata": {},
   "source": [
    "## Answer Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1e4570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "money_words = [\n",
    "    'dollar', 'euro', 'pound', 'yen', 'payment', 'price', 'cost', 'fee', 'salary',\n",
    "    'profit', 'revenue', 'income', 'expenditure', 'budget',\n",
    "    'bank', 'account', 'credit', 'loan', 'interest', 'GDP', 'inflation', 'deflation',\n",
    "    'exchange rate', 'stock', 'bond', 'dividend', 'capital', 'tax', 'duty', 'levy',\n",
    "    'refund', 'revenue', 'expense', 'loss', 'cash', 'credit card', 'check', 'PayPal','amount'\n",
    "]\n",
    "date_related_words = [\n",
    "    'celebration', 'anniversary', 'ceremony', 'festival', 'holiday', 'occasion', 'commemoration',\n",
    "    'era', 'century', 'decade', 'generation', 'period', 'epoch', 'age',\n",
    "    'timeline', 'chronology', 'schedule', 'agenda', 'timetable', 'deadline', 'due date', 'expiry date',\n",
    "    'duration', 'timeframe', 'interval', 'period', 'length', 'span', 'term', 'periodicity',\n",
    "    'yesterday', 'today', 'tomorrow', 'past', 'present', 'future', 'then', 'now',\n",
    "    'spring', 'summer', 'autumn', 'winter', 'monsoon', 'rainy season', 'dry season', 'harvest season',\n",
    "    'date', 'day', 'week', 'month', 'year', 'decade', 'century', 'millennium',\n",
    "    'age', 'youth', 'aging', 'seniority', 'life stage'\n",
    "]\n",
    "person_question_words = ['who', 'whose', 'whom', 'name', 'identity', 'character', 'individual', 'subject', 'figure', 'protagonist']\n",
    "\n",
    "gpe_question_words = ['where', 'location', 'place', 'country', 'city', 'state', 'region', 'province', 'town', 'area','capital']\n",
    "\n",
    "def answertype(article, question):\n",
    "\n",
    "    context=extract_relevant_sentences_tfidf(article,question)\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    \n",
    "    if questiontype(question):\n",
    "        t = 'DESCRIPTIVE'\n",
    "        word = word_tokenize(question.lower())\n",
    "        if any(x in word for x in person_question_words):\n",
    "            t = 'PERSON'\n",
    "        elif 'where' in word:\n",
    "            t = 'GPE'\n",
    "        elif any(x in word for x in date_related_words):\n",
    "            t = 'DATE'\n",
    "        elif 'when' in word or any(x in word for x in date_related_words):\n",
    "            t = 'DATE'\n",
    "        elif any(x in word for x in money_words):\n",
    "            t= 'MONEY'\n",
    "        \n",
    "        coref_clusters=create_cluster.getClusters()\n",
    "        # Perform further processing based on answer type\n",
    "        if t == 'DESCRIPTIVE':\n",
    "            \n",
    "            return question\n",
    "        \n",
    "        else:\n",
    "            # Perform processing based on entity extraction\n",
    "            # Extract entities of the identified answer type from the context\n",
    "            \n",
    "            \n",
    "            doc = nlp(context)\n",
    "            \n",
    "            entities = [ent.text for ent in doc.ents if ent.label_ == t]\n",
    "            #events = extract_events(doc)  # Extract events from the context\n",
    "            #relations = extract_relations(doc)  # Extract relations between entities\n",
    "            \n",
    "            if coref_clusters:\n",
    "                # Check if the first entity is in any head cluster\n",
    "                first_entity = entities[0] if entities else None\n",
    "                for cluster in coref_clusters:\n",
    "                    if first_entity and first_entity in cluster.main.text:\n",
    "                        return cluster.main.text  # Return the head of the coreference cluster\n",
    "\n",
    "            # If entities of the answer type are found, return the first one\n",
    "            if entities:\n",
    "                return entities[0]\n",
    "            #elif events:\n",
    "              #  return events[0]\n",
    "           # elif relations:\n",
    "               # return relations[0]\n",
    "            else:\n",
    "                # If no entities, events, or relations are found, return the context itself\n",
    "                return \"Couldn't find the answer in the context.\"\n",
    "\n",
    "    else:\n",
    "        \n",
    "        return \"Not A Question!\"\n",
    "\n",
    "\n",
    "def questiontype(question):\n",
    "    # Define question tags\n",
    "    questiontags = ['WP', 'WDT', 'WP$', 'WRB']\n",
    "\n",
    "    # Tokenize and tag the question\n",
    "    question_POS = pos_tag(word_tokenize(question.lower()))\n",
    "    \n",
    "    # Identify question tags\n",
    "    question_tags = [token for token, tag in question_POS if tag in questiontags]\n",
    "\n",
    "    # Check if there is only one question tag and it's not \"what\"\n",
    "    if len(question_tags) == 1 :\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "#def extract_events(doc):\n",
    " #   events = []\n",
    "  #  for token in doc:\n",
    "   #     if token.pos_ == \"VERB\":\n",
    "    #        events.append(token.text)\n",
    "    #return events\n",
    "\n",
    "#def extract_relations(doc):\n",
    " #   relations = []\n",
    "  #  for token in doc:\n",
    "   #     if token.dep_ == \"nsubj\" and token.head.pos_ == \"VERB\":\n",
    "    #        # Extract relation in the form of subject-verb\n",
    "     #       relation = f\"{token.text}-{token.head.text}\"\n",
    "      #      relations.append(relation)\n",
    "    #return relations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a34f55",
   "metadata": {},
   "source": [
    "## Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f995607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Mr. Ubelmann\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example relevant context and question\n",
    "question = \"Who founded the company Iconem\"\n",
    "\n",
    "\n",
    "\n",
    "# Extract the answer\n",
    "answer = answertype(getArticle(17307), question)\n",
    "print(\"Answer:\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f47d4b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_questions=pd.read_csv(\"new_questions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "106dc45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yves Ubelmann\n",
      "Mr. Ubelmann\n",
      "Martinez\n",
      "Louvre\n",
      "Houmam Saad\n",
      "Ubelmann\n",
      "President François Hollande\n",
      "Palmyra\n",
      "President François Hollande\n",
      "Couldn't find the answer in the context.\n",
      "Yves Ubelmann\n",
      "Couldn't find the answer in the context.\n",
      "Cheikhmous Ali\n",
      "Cheikhmous Ali\n",
      "Cheikhmous Ali\n",
      "Cheikhmous Ali\n",
      "President François Hollande\n",
      "Hollande\n",
      "France\n",
      "Couldn't find the answer in the context.\n",
      "Zoraida Mu'iz and her family\n",
      "Couldn't find the answer in the context.\n",
      "Zoraida Mu'iz\n",
      "Not A Question!\n",
      "Jos' Mu'iz\n",
      "Ms. Mu'iz\n",
      "Jos' Jr.\n",
      "Jos' Jr.\n",
      "Jesus\n",
      "Jesus\n",
      "Jos' Mu'iz\n",
      "Couldn't find the answer in the context.\n",
      "Surgeons\n",
      "Mr. Mu'iz\n",
      "Jesus\n",
      "Jesus\n",
      "Zoraida Mu'iz\n",
      "Ms. Mu'iz\n",
      "Maria\n",
      "Couldn't find the answer in the context.\n",
      "Precision Score: 0.25\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Initialize lists to store expected and extracted answers\n",
    "expected_answers = []\n",
    "extracted_answers = []\n",
    "\n",
    "for index, row in test_questions.iterrows():\n",
    "    question = row['question']\n",
    "    article_id = row['article']\n",
    "    expected_answer = row['answer']\n",
    "    \n",
    "    # Fetch the article based on the article_id\n",
    "    test_article = getArticle(article_id)\n",
    "    \n",
    "    # Extract relevant sentences from the article\n",
    "    relevant_sentences = extract_relevant_sentences_hf(test_article, question)\n",
    "    \n",
    "    # Extract the answer\n",
    "    answer = answertype(relevant_sentences, question)\n",
    "    \n",
    "    # Append expected and extracted answers to the lists\n",
    "    expected_answers.append(expected_answer)\n",
    "    print(expected_answer)\n",
    "    extracted_answers.append(answer)\n",
    "    print(answer)\n",
    "\n",
    "# Compute the precision score\n",
    "precision = f1_score(expected_answers, extracted_answers, average='micro')\n",
    "\n",
    "print(\"Precision Score:\", precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b92a1b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yves Ubelmann\n",
      "Ubelmann\n",
      "Martinez\n",
      "Martinez\n",
      "Houmam Saad\n",
      "Cheikhmous Ali\n",
      "President François Hollande\n",
      "Palmyra\n",
      "President François Hollande\n",
      "Couldn't find the answer in the context.\n",
      "Yves Ubelmann\n",
      "Nineveh\n",
      "Cheikhmous Ali\n",
      "Cheikhmous Ali\n",
      "Cheikhmous Ali\n",
      "Cheikhmous Ali\n",
      "President François Hollande\n",
      "Mr. Hollande\n",
      "France\n",
      "Palmyra\n",
      "Zoraida Mu'iz and her family\n",
      "Dickens\n",
      "Zoraida Mu'iz\n",
      "Not A Question!\n",
      "Jos' Mu'iz\n",
      "Mu'iz\n",
      "Jos' Jr.\n",
      "Jesus\n",
      "Jesus\n",
      "Jesus\n",
      "Jos' Mu'iz\n",
      "Ms. Mu'iz\n",
      "Surgeons\n",
      "Mr. Mu'iz\n",
      "Jesus\n",
      "Jesus\n",
      "Zoraida Mu'iz\n",
      "Mu'iz\n",
      "Maria\n",
      "Maria\n",
      "Precision Score: 0.3\n"
     ]
    }
   ],
   "source": [
    "expected_answers = []\n",
    "extracted_answers = []\n",
    "\n",
    "for index, row in test_questions.iterrows():\n",
    "    question = row['question']\n",
    "    article_id = row['article']\n",
    "    expected_answer = row['answer']\n",
    "    \n",
    "    # Fetch the article based on the article_id\n",
    "    test_article = getArticle(article_id)\n",
    "    \n",
    "    # Extract relevant sentences from the article\n",
    "    relevant_sentences = extract_relevant_sentences_tfidf(test_article, question)\n",
    "    \n",
    "    # Extract the answer\n",
    "    answer = answertype(relevant_sentences, question)\n",
    "    \n",
    "    # Append expected and extracted answers to the lists\n",
    "    expected_answers.append(expected_answer)\n",
    "    print(expected_answer)\n",
    "    extracted_answers.append(answer)\n",
    "    print(answer)\n",
    "\n",
    "# Compute the precision score\n",
    "precision = f1_score(expected_answers, extracted_answers, average='micro')\n",
    "\n",
    "print(\"Precision Score:\", precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "435e2586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.\n",
      "Question: In what country is Normandy located?\n",
      "Predicted Answer: In what country is Normandy located?\n",
      "Plausible Answer: France\n",
      "Question: When were the Normans in Normandy?\n",
      "Predicted Answer: the first half of the 10th century\n",
      "Plausible Answer: 10th and 11th centuries\n",
      "Question: From which countries did the Norse originate?\n",
      "Predicted Answer: From which countries did the Norse originate?\n",
      "Plausible Answer: Denmark, Iceland and Norway\n",
      "Question: Who was the Norse leader?\n",
      "Predicted Answer: Norse\n",
      "Plausible Answer: Rollo\n",
      "Question: What century did the Normans first gain their separate identity?\n",
      "Predicted Answer: The Normans (Norman: Nourmands; French: Normands; Latin: Normanni)\n",
      "Plausible Answer: 10th century\n",
      "Question: Who gave their name to Normandy in the 1000's and 1100's\n",
      "Predicted Answer: The Normans (Norman: Nourmands; French: Normands; Latin: Normanni)\n",
      "Plausible Answer: Normans\n",
      "Question: What is France a region of?\n",
      "Predicted Answer: What is France a region of?\n",
      "Plausible Answer: Normandy\n",
      "Question: Who did King Charles III swear fealty to?\n",
      "Predicted Answer: Norse\n",
      "Plausible Answer: Rollo\n",
      "Question: When did the Frankish identity emerge?\n",
      "Predicted Answer: The Normans (Norman: Nourmands; French: Normands; Latin: Normanni)\n",
      "Plausible Answer: 10th century\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"SQUAD-Testing.json\", \"r\") as f:\n",
    "    squad_test = json.load(f)\n",
    "\n",
    "\n",
    "for data_item in squad_test[\"data\"]:\n",
    "    # Read the context\n",
    "    context = data_item[\"context\"]\n",
    "    print(\"Context:\", context)\n",
    "\n",
    "    # Iterate through the questions\n",
    "    for question_item in data_item[\"questions\"]:\n",
    "        question = question_item[\"question\"]\n",
    "        print(\"Question:\", question)\n",
    "        predicted_answer=answertype(context,question)\n",
    "        \n",
    "        plausible_answers = question_item[\"plausible_answers\"]\n",
    "        for answer in plausible_answers:\n",
    "            answer_text = answer[\"text\"]\n",
    "            print(\"Predicted Answer:\",predicted_answer)\n",
    "            print(\"Plausible Answer:\", answer_text)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9f7807",
   "metadata": {},
   "source": [
    "## User Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1ca999c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb13fd376ab4a44929a6933df039018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Question:', placeholder='Enter your question')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aaf43b507ce46f2b58a5be6583d0ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=0, description='Article Number:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c168c95ed77b45ee91d82973a98e4e31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a00883cbf2c4e93a40a8699410ab785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Get Answer', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display,clear_output\n",
    "\n",
    "# Define input widgets\n",
    "question_input = widgets.Text(description='Question:', placeholder='Enter your question', disabled=False)\n",
    "article_input = widgets.IntText(description='Article Number:', value=0, disabled=False)\n",
    "answer_output=widgets.Output(description=\"Answer\")\n",
    "\n",
    "\n",
    "\n",
    "# Define a callback function to be called when the button is clicked\n",
    "def on_button_click(b):\n",
    "    question = question_input.value\n",
    "    article_number = article_input.value\n",
    "    if question and article_number:\n",
    "        article=getArticle(article_number)\n",
    "    else:\n",
    "        print(\"Give Proper Questiona and Article\")\n",
    "    with answer_output:\n",
    "        clear_output(wait=True)\n",
    "    \n",
    "    # Display the answer\n",
    "    with answer_output:\n",
    "        answer = answertype(article, question)\n",
    "        print(\"Answer:\",answer)\n",
    "\n",
    "# Create a button widget\n",
    "button = widgets.Button(description='Get Answer')\n",
    "button.on_click(on_button_click)\n",
    "\n",
    "# Display the input widgets and button\n",
    "display(question_input, article_input,answer_output, button)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3a91b4",
   "metadata": {},
   "source": [
    "## B. References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e27fcb3",
   "metadata": {},
   "source": [
    "Aakansha281 (no date) Information-retrieval-based-question-answering-system/qa_system.ipynb at master · AAKANSHA281/information-retrieval-based-question-answering-system, GitHub. Available at: https://github.com/Aakansha281/Information-Retrieval-based-Question-Answering-System/blob/master/QA_System.ipynb (Accessed: 10 April 2024). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d0a666",
   "metadata": {},
   "source": [
    "Used Chat GPT - 3.5 To reformat the code for error and used Prompts like \"What is wrong here?, What can be changed?,\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7553c1",
   "metadata": {},
   "source": [
    "## C. Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc82776",
   "metadata": {},
   "source": [
    "* Reading Dataset and Pre-Processing\n",
    "* Coreference Resolution\n",
    "* Test-Matching Utility\n",
    "* Answer Extraction\n",
    "* Testing\n",
    "* User Interaction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
